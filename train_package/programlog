INFO:root:select coin online from 2020-08-31 13:31 to 2020-09-30 13:31
INFO:root:Successfully got coinlist
DEBUG:root:Selected coins are: ['reversed_USDT', 'ETH', 'XRP', 'TRX', 'XMR', 'LTC', 'BCHSV', 'XEM', 'BCHABC', 'ATOM', 'STR']
INFO:root:feature type list is ['close', 'high', 'low']
DEBUG:root:buffer_bias is 0.000050
INFO:root:the number of training examples is 14037, of test examples is 1226
DEBUG:root:the training set is from 50 to 14086
DEBUG:root:the test set is from 14087 to 15312
INFO:root:upper bound in test is 2584.1192522210276
INFO:root:average time for data accessing is 6.690025329589844e-07
INFO:root:average time for training is 2.8508186340332032e-05
INFO:root:get better model at 0 steps, whose test portfolio value is tensor(0.8979, grad_fn=<ProdBackward0>)
INFO:root:==============================
INFO:root:step 0
INFO:root:------------------------------
INFO:root:training loss is tensor(-8.9369e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8979, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.1653e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000092
log mean without commission fee is -0.000086

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005758101940155029
INFO:root:average time for training is 0.006090033769607544
INFO:root:get better model at 1000 steps, whose test portfolio value is tensor(0.8980, grad_fn=<ProdBackward0>)
INFO:root:==============================
INFO:root:step 1000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0446e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8980, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.1595e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000092
log mean without commission fee is -0.000086

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005615429878234864
INFO:root:average time for training is 0.00601335072517395
INFO:root:==============================
INFO:root:step 2000
INFO:root:------------------------------
INFO:root:training loss is tensor(-8.8454e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8980, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.1596e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000092
log mean without commission fee is -0.000086

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005643670558929443
INFO:root:average time for training is 0.006027726888656616
INFO:root:==============================
INFO:root:step 3000
INFO:root:------------------------------
INFO:root:training loss is tensor(-8.9470e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8976, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.1954e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000092
log mean without commission fee is -0.000086

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005625505447387695
INFO:root:average time for training is 0.006009566068649292
INFO:root:==============================
INFO:root:step 4000
INFO:root:------------------------------
INFO:root:training loss is tensor(-8.9782e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8973, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.2232e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000092
log mean without commission fee is -0.000086

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005669159889221192
INFO:root:average time for training is 0.006019973993301391
INFO:root:==============================
INFO:root:step 5000
INFO:root:------------------------------
INFO:root:training loss is tensor(-8.9981e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8975, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.2084e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000092
log mean without commission fee is -0.000086

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005649423599243164
INFO:root:average time for training is 0.006030946969985962
INFO:root:==============================
INFO:root:step 6000
INFO:root:------------------------------
INFO:root:training loss is tensor(-8.9216e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8970, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.2510e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000093
log mean without commission fee is -0.000087

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005625371932983399
INFO:root:average time for training is 0.00601838493347168
INFO:root:==============================
INFO:root:step 7000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0380e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8971, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.2437e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000092
log mean without commission fee is -0.000087

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005647764205932617
INFO:root:average time for training is 0.006017579555511475
INFO:root:==============================
INFO:root:step 8000
INFO:root:------------------------------
INFO:root:training loss is tensor(-8.8952e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8970, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.2470e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000092
log mean without commission fee is -0.000087

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005648753643035889
INFO:root:average time for training is 0.006009146690368652
INFO:root:==============================
INFO:root:step 9000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0287e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8975, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.1993e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000092
log mean without commission fee is -0.000086

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005658690929412842
INFO:root:average time for training is 0.006013890266418457
INFO:root:==============================
INFO:root:step 10000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0927e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8977, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.1874e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000092
log mean without commission fee is -0.000086

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005625333786010743
INFO:root:average time for training is 0.006008383274078369
INFO:root:==============================
INFO:root:step 11000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0844e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8971, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.2423e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000092
log mean without commission fee is -0.000086

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005630671977996827
INFO:root:average time for training is 0.006015021085739136
INFO:root:==============================
INFO:root:step 12000
INFO:root:------------------------------
INFO:root:training loss is tensor(-8.9649e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8968, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.2746e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000093
log mean without commission fee is -0.000087

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005666365623474122
INFO:root:average time for training is 0.006082905769348145
INFO:root:==============================
INFO:root:step 13000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0055e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8969, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.2562e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000093
log mean without commission fee is -0.000087

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005477001667022705
INFO:root:average time for training is 0.005880239486694336
INFO:root:==============================
INFO:root:step 14000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0502e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8969, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.2583e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000093
log mean without commission fee is -0.000087

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005467519760131836
INFO:root:average time for training is 0.00586187744140625
INFO:root:==============================
INFO:root:step 15000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0122e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8968, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.2705e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000093
log mean without commission fee is -0.000087

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005495829582214355
INFO:root:average time for training is 0.005867603302001953
INFO:root:==============================
INFO:root:step 16000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0504e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8968, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.2696e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000093
log mean without commission fee is -0.000087

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005512099266052246
INFO:root:average time for training is 0.00588333797454834
INFO:root:==============================
INFO:root:step 17000
INFO:root:------------------------------
INFO:root:training loss is tensor(-8.9007e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8965, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.2976e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000093
log mean without commission fee is -0.000087

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005489504337310791
INFO:root:average time for training is 0.005862481832504272
INFO:root:==============================
INFO:root:step 18000
INFO:root:------------------------------
INFO:root:training loss is tensor(-8.9371e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8965, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.2974e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000093
log mean without commission fee is -0.000087

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005177974700927735
INFO:root:average time for training is 0.005723931550979614
INFO:root:==============================
INFO:root:step 19000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0128e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8964, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.3068e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000093
log mean without commission fee is -0.000087

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005510756969451904
INFO:root:average time for training is 0.005877909421920777
INFO:root:==============================
INFO:root:step 20000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0535e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8963, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.3213e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000093
log mean without commission fee is -0.000087

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005498960018157959
INFO:root:average time for training is 0.005868460178375244
INFO:root:==============================
INFO:root:step 21000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0320e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8961, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.3329e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000093
log mean without commission fee is -0.000087

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005498895645141602
INFO:root:average time for training is 0.005884321451187134
INFO:root:==============================
INFO:root:step 22000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1009e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8960, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.3446e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000093
log mean without commission fee is -0.000087

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005476863384246826
INFO:root:average time for training is 0.005851634979248047
INFO:root:==============================
INFO:root:step 23000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0561e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8956, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.3809e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000094
log mean without commission fee is -0.000088

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005482466220855713
INFO:root:average time for training is 0.005867517232894898
INFO:root:==============================
INFO:root:step 24000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0766e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8955, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.3953e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000094
log mean without commission fee is -0.000088

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005347213745117188
INFO:root:average time for training is 0.00579699444770813
INFO:root:==============================
INFO:root:step 25000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0495e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8953, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.4121e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000094
log mean without commission fee is -0.000088

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005224225521087647
INFO:root:average time for training is 0.0057476480007171635
INFO:root:==============================
INFO:root:step 26000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0664e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8952, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.4218e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000094
log mean without commission fee is -0.000088

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005516297817230225
INFO:root:average time for training is 0.005907601594924926
INFO:root:==============================
INFO:root:step 27000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0280e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8952, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.4243e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000094
log mean without commission fee is -0.000088

INFO:root:==============================

INFO:root:average time for data accessing is 0.000551328420639038
INFO:root:average time for training is 0.005920885562896728
INFO:root:==============================
INFO:root:step 28000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1318e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8952, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.4217e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000094
log mean without commission fee is -0.000088

INFO:root:==============================

INFO:root:average time for data accessing is 0.000547898530960083
INFO:root:average time for training is 0.005875992774963379
INFO:root:==============================
INFO:root:step 29000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1013e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8948, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.4609e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000095
log mean without commission fee is -0.000089

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005481834411621094
INFO:root:average time for training is 0.00587892484664917
INFO:root:==============================
INFO:root:step 30000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0334e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8946, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.4776e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000095
log mean without commission fee is -0.000089

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005488424301147461
INFO:root:average time for training is 0.005865565061569214
INFO:root:==============================
INFO:root:step 31000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1400e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8946, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.4795e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000095
log mean without commission fee is -0.000089

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005470950603485107
INFO:root:average time for training is 0.005876983642578125
INFO:root:==============================
INFO:root:step 32000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1450e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8945, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.4851e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000095
log mean without commission fee is -0.000089

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005475268363952637
INFO:root:average time for training is 0.005865365982055664
INFO:root:==============================
INFO:root:step 33000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1092e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8944, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.4966e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000095
log mean without commission fee is -0.000089

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005474283695220948
INFO:root:average time for training is 0.005874248027801514
INFO:root:==============================
INFO:root:step 34000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1204e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8943, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.5110e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000095
log mean without commission fee is -0.000089

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005473639965057373
INFO:root:average time for training is 0.0058616364002227785
INFO:root:==============================
INFO:root:step 35000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1266e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8940, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.5408e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000095
log mean without commission fee is -0.000089

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005680875778198242
INFO:root:average time for training is 0.0060710997581481935
INFO:root:==============================
INFO:root:step 36000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1433e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8938, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.5589e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000089

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005498380661010742
INFO:root:average time for training is 0.005884707450866699
INFO:root:==============================
INFO:root:step 37000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1395e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8936, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.5764e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005445897579193116
INFO:root:average time for training is 0.005870383501052856
INFO:root:==============================
INFO:root:step 38000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1443e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8936, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.5741e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005503871440887451
INFO:root:average time for training is 0.005866089344024658
INFO:root:==============================
INFO:root:step 39000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1799e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8932, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6105e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.000550666332244873
INFO:root:average time for training is 0.005891649007797241
INFO:root:==============================
INFO:root:step 40000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1453e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8930, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6288e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005490307807922364
INFO:root:average time for training is 0.0058635823726654055
INFO:root:==============================
INFO:root:step 41000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1381e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8931, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6195e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005466258525848389
INFO:root:average time for training is 0.00586559534072876
INFO:root:==============================
INFO:root:step 42000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1698e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8932, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6085e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.000543940544128418
INFO:root:average time for training is 0.005872014999389648
INFO:root:==============================
INFO:root:step 43000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1841e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8930, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6280e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.000545189619064331
INFO:root:average time for training is 0.005880645751953125
INFO:root:==============================
INFO:root:step 44000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.0977e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8930, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6278e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005478489398956298
INFO:root:average time for training is 0.005873382568359375
INFO:root:==============================
INFO:root:step 45000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1786e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8930, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6340e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005493388175964356
INFO:root:average time for training is 0.005892200231552124
INFO:root:==============================
INFO:root:step 46000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1689e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8931, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6216e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005481514930725098
INFO:root:average time for training is 0.005877694606781006
INFO:root:==============================
INFO:root:step 47000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2008e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8932, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6155e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005463948249816895
INFO:root:average time for training is 0.005869660139083862
INFO:root:==============================
INFO:root:step 48000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1975e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8930, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6281e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005515947341918945
INFO:root:average time for training is 0.005851431369781494
INFO:root:==============================
INFO:root:step 49000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2011e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8931, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6257e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005486836433410645
INFO:root:average time for training is 0.005860037803649902
INFO:root:==============================
INFO:root:step 50000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1388e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8930, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6341e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000096
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005495116710662842
INFO:root:average time for training is 0.005859794139862061
INFO:root:==============================
INFO:root:step 51000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2100e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8928, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6512e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000097
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005484046936035156
INFO:root:average time for training is 0.0058560407161712645
INFO:root:==============================
INFO:root:step 52000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2667e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8925, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6743e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000097
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005487070083618164
INFO:root:average time for training is 0.005859123945236206
INFO:root:==============================
INFO:root:step 53000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1834e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8926, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6701e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000097
log mean without commission fee is -0.000090

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005497071743011475
INFO:root:average time for training is 0.005869106292724609
INFO:root:==============================
INFO:root:step 54000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1932e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8924, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6850e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000097
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005216739177703858
INFO:root:average time for training is 0.0057337191104888914
INFO:root:==============================
INFO:root:step 55000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1497e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8924, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6898e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000097
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005479259490966797
INFO:root:average time for training is 0.00592525577545166
INFO:root:==============================
INFO:root:step 56000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2101e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8924, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6850e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000097
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005513834953308106
INFO:root:average time for training is 0.005862918853759766
INFO:root:==============================
INFO:root:step 57000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1699e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8924, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.6913e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000097
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005496885776519776
INFO:root:average time for training is 0.005869536399841308
INFO:root:==============================
INFO:root:step 58000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2266e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8922, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7083e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000097
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005489130020141602
INFO:root:average time for training is 0.005870673894882202
INFO:root:==============================
INFO:root:step 59000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1703e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8920, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7241e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000097
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005466048717498779
INFO:root:average time for training is 0.00585068416595459
INFO:root:==============================
INFO:root:step 60000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2067e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8920, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7240e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000097
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005486629009246826
INFO:root:average time for training is 0.005870810985565186
INFO:root:==============================
INFO:root:step 61000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2260e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8919, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7374e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000097
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005464251041412354
INFO:root:average time for training is 0.005849778652191162
INFO:root:==============================
INFO:root:step 62000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2199e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8917, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7517e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005516924858093261
INFO:root:average time for training is 0.005875258445739746
INFO:root:==============================
INFO:root:step 63000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2292e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8916, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7665e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005471653938293457
INFO:root:average time for training is 0.005869383096694946
INFO:root:==============================
INFO:root:step 64000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2456e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8916, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7618e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005474262237548828
INFO:root:average time for training is 0.005879181385040283
INFO:root:==============================
INFO:root:step 65000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2254e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8917, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7592e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005524373054504395
INFO:root:average time for training is 0.0059182305335998536
INFO:root:==============================
INFO:root:step 66000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1911e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8914, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7793e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005517566204071045
INFO:root:average time for training is 0.005891870021820069
INFO:root:==============================
INFO:root:step 67000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2625e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8916, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7630e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005481817722320557
INFO:root:average time for training is 0.005857279062271118
INFO:root:==============================
INFO:root:step 68000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2470e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8916, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7655e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005416028499603271
INFO:root:average time for training is 0.005832571029663086
INFO:root:==============================
INFO:root:step 69000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2338e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8913, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7898e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005507495403289795
INFO:root:average time for training is 0.005892908096313477
INFO:root:==============================
INFO:root:step 70000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2102e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8911, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8143e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005635461807250977
INFO:root:average time for training is 0.005956279993057251
INFO:root:==============================
INFO:root:step 71000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2968e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8913, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7913e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005474648475646972
INFO:root:average time for training is 0.00592691421508789
INFO:root:==============================
INFO:root:step 72000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2643e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8911, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8120e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005541331768035889
INFO:root:average time for training is 0.005914697647094727
INFO:root:==============================
INFO:root:step 73000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1699e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8911, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8116e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005489282608032226
INFO:root:average time for training is 0.005869299650192261
INFO:root:==============================
INFO:root:step 74000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2864e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8915, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7783e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000091

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005518817901611329
INFO:root:average time for training is 0.005865206241607666
INFO:root:==============================
INFO:root:step 75000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2450e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8912, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8063e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005396203994750976
INFO:root:average time for training is 0.005829235076904297
INFO:root:==============================
INFO:root:step 76000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2292e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8911, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8093e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005470204353332519
INFO:root:average time for training is 0.005857359886169433
INFO:root:==============================
INFO:root:step 77000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3042e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8912, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8023e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.000519430160522461
INFO:root:average time for training is 0.005727894067764282
INFO:root:==============================
INFO:root:step 78000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.1981e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8911, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8082e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005484504699707031
INFO:root:average time for training is 0.005859172582626343
INFO:root:==============================
INFO:root:step 79000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2661e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8912, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8000e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005815820693969726
INFO:root:average time for training is 0.006307233572006226
INFO:root:==============================
INFO:root:step 80000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2730e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8912, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8074e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.000548447847366333
INFO:root:average time for training is 0.005880235910415649
INFO:root:==============================
INFO:root:step 81000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2351e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8912, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8041e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005345563888549805
INFO:root:average time for training is 0.005811235427856445
INFO:root:==============================
INFO:root:step 82000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2793e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8913, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.7943e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005506401062011719
INFO:root:average time for training is 0.005907892227172851
INFO:root:==============================
INFO:root:step 83000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2069e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8909, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8294e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005184066295623779
INFO:root:average time for training is 0.0057154541015625
INFO:root:==============================
INFO:root:step 84000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2110e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8907, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8513e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005502817630767822
INFO:root:average time for training is 0.005855784654617309
INFO:root:==============================
INFO:root:step 85000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2555e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8908, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8396e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005468156337738037
INFO:root:average time for training is 0.005845635414123535
INFO:root:==============================
INFO:root:step 86000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2344e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8909, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8284e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005487961769104004
INFO:root:average time for training is 0.005867992401123047
INFO:root:==============================
INFO:root:step 87000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2372e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8907, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8468e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005200068950653076
INFO:root:average time for training is 0.005743706941604614
INFO:root:==============================
INFO:root:step 88000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2848e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8909, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8357e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005612082481384278
INFO:root:average time for training is 0.006018872976303101
INFO:root:==============================
INFO:root:step 89000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2493e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8909, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8363e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005502054691314697
INFO:root:average time for training is 0.005869004964828491
INFO:root:==============================
INFO:root:step 90000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2308e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8908, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8371e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005492968559265137
INFO:root:average time for training is 0.005871399164199829
INFO:root:==============================
INFO:root:step 91000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3003e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8907, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8521e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005522656440734863
INFO:root:average time for training is 0.005896472454071045
INFO:root:==============================
INFO:root:step 92000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3226e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8908, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8382e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005512387752532959
INFO:root:average time for training is 0.005892247438430786
INFO:root:==============================
INFO:root:step 93000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2306e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8905, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8725e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.000549576997756958
INFO:root:average time for training is 0.005873220920562744
INFO:root:==============================
INFO:root:step 94000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2304e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8905, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8733e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005502967834472656
INFO:root:average time for training is 0.005879573345184326
INFO:root:==============================
INFO:root:step 95000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2467e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8905, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8683e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005479674339294434
INFO:root:average time for training is 0.005878170967102051
INFO:root:==============================
INFO:root:step 96000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2206e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8908, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8430e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005453982353210449
INFO:root:average time for training is 0.005864488363265991
INFO:root:==============================
INFO:root:step 97000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2510e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8907, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8483e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000098
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005487959384918213
INFO:root:average time for training is 0.005890700817108154
INFO:root:==============================
INFO:root:step 98000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3077e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8907, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8519e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.000552466869354248
INFO:root:average time for training is 0.005923747777938843
INFO:root:==============================
INFO:root:step 99000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2318e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8906, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8566e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005496337413787842
INFO:root:average time for training is 0.005852738857269287
INFO:root:==============================
INFO:root:step 100000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2794e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8906, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8608e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000092

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005522499084472656
INFO:root:average time for training is 0.005924954175949097
INFO:root:==============================
INFO:root:step 101000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2690e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8901, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9050e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005484302043914795
INFO:root:average time for training is 0.005886396884918213
INFO:root:==============================
INFO:root:step 102000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2889e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8902, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8961e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.00054585862159729
INFO:root:average time for training is 0.005847759962081909
INFO:root:==============================
INFO:root:step 103000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2802e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8902, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9025e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005490386486053467
INFO:root:average time for training is 0.005879340648651123
INFO:root:==============================
INFO:root:step 104000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3219e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8902, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8939e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005201928615570069
INFO:root:average time for training is 0.00573593020439148
INFO:root:==============================
INFO:root:step 105000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2901e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8902, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.8949e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005457730293273926
INFO:root:average time for training is 0.005867685794830322
INFO:root:==============================
INFO:root:step 106000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2635e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8901, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9091e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005476748943328857
INFO:root:average time for training is 0.005851030349731445
INFO:root:==============================
INFO:root:step 107000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2979e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8900, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9195e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005504331588745118
INFO:root:average time for training is 0.005871938705444336
INFO:root:==============================
INFO:root:step 108000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2951e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8900, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9191e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.000549077033996582
INFO:root:average time for training is 0.005872940540313721
INFO:root:==============================
INFO:root:step 109000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2810e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8898, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9345e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005484082698822021
INFO:root:average time for training is 0.005875745058059692
INFO:root:==============================
INFO:root:step 110000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3508e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8899, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9258e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005473847389221192
INFO:root:average time for training is 0.0058694202899932865
INFO:root:==============================
INFO:root:step 111000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2178e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8899, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9316e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005468709468841553
INFO:root:average time for training is 0.005861849308013916
INFO:root:==============================
INFO:root:step 112000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2829e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8899, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9299e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005506501197814942
INFO:root:average time for training is 0.005875636100769043
INFO:root:==============================
INFO:root:step 113000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3372e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8899, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9274e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005498149394989013
INFO:root:average time for training is 0.005912425279617309
INFO:root:==============================
INFO:root:step 114000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2879e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8897, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9453e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005537681579589844
INFO:root:average time for training is 0.005924800872802735
INFO:root:==============================
INFO:root:step 115000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2769e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8897, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9460e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005501654148101807
INFO:root:average time for training is 0.00590816068649292
INFO:root:==============================
INFO:root:step 116000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3442e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8898, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9399e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005196571350097656
INFO:root:average time for training is 0.0057331774234771725
INFO:root:==============================
INFO:root:step 117000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2830e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8897, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9495e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005497245788574219
INFO:root:average time for training is 0.005878615140914917
INFO:root:==============================
INFO:root:step 118000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3076e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8897, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9492e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005487215518951416
INFO:root:average time for training is 0.005850148677825928
INFO:root:==============================
INFO:root:step 119000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2969e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8896, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9521e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005472114086151123
INFO:root:average time for training is 0.005864157676696778
INFO:root:==============================
INFO:root:step 120000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3262e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8898, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9399e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005509459972381592
INFO:root:average time for training is 0.005874850034713745
INFO:root:==============================
INFO:root:step 121000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2679e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8899, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9309e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005360348224639893
INFO:root:average time for training is 0.0058162822723388675
INFO:root:==============================
INFO:root:step 122000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2576e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8896, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9548e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005451085567474366
INFO:root:average time for training is 0.00586153244972229
INFO:root:==============================
INFO:root:step 123000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3191e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8897, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9455e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000099
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005486743450164794
INFO:root:average time for training is 0.00586475920677185
INFO:root:==============================
INFO:root:step 124000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3146e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8896, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9557e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005472028255462647
INFO:root:average time for training is 0.005881583452224732
INFO:root:==============================
INFO:root:step 125000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2768e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8893, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9805e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005514724254608155
INFO:root:average time for training is 0.005890668392181397
INFO:root:==============================
INFO:root:step 126000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3213e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8893, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9811e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005507335662841797
INFO:root:average time for training is 0.005867842197418213
INFO:root:==============================
INFO:root:step 127000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3681e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8893, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9869e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.000520611047744751
INFO:root:average time for training is 0.005721812725067139
INFO:root:==============================
INFO:root:step 128000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2763e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8893, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9880e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005509274005889893
INFO:root:average time for training is 0.005907521963119507
INFO:root:==============================
INFO:root:step 129000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3260e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8893, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9850e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005246899127960205
INFO:root:average time for training is 0.005771753787994385
INFO:root:==============================
INFO:root:step 130000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2746e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8892, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9911e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005469672679901123
INFO:root:average time for training is 0.0058521730899810795
INFO:root:==============================
INFO:root:step 131000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2931e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8893, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9863e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005404589176177979
INFO:root:average time for training is 0.005841203689575195
INFO:root:==============================
INFO:root:step 132000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2856e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8892, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9905e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005241279602050781
INFO:root:average time for training is 0.005729515552520752
INFO:root:==============================
INFO:root:step 133000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3464e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8894, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9792e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.000546910285949707
INFO:root:average time for training is 0.005870072603225708
INFO:root:==============================
INFO:root:step 134000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2558e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8893, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9874e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.000547245979309082
INFO:root:average time for training is 0.005845895290374756
INFO:root:==============================
INFO:root:step 135000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2676e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8893, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9838e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005417633056640625
INFO:root:average time for training is 0.005828218936920166
INFO:root:==============================
INFO:root:step 136000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3388e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8894, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9718e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005452382564544678
INFO:root:average time for training is 0.005871203422546387
INFO:root:==============================
INFO:root:step 137000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3076e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8894, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9780e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005290749073028565
INFO:root:average time for training is 0.005766966104507446
INFO:root:==============================
INFO:root:step 138000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2608e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8894, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9755e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005471639633178711
INFO:root:average time for training is 0.005880527496337891
INFO:root:==============================
INFO:root:step 139000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2465e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8895, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9670e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005285089015960693
INFO:root:average time for training is 0.005768249034881592
INFO:root:==============================
INFO:root:step 140000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3216e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8893, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9812e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005465166568756104
INFO:root:average time for training is 0.005845646381378174
INFO:root:==============================
INFO:root:step 141000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3864e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8892, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9904e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005517287254333496
INFO:root:average time for training is 0.005880993127822876
INFO:root:==============================
INFO:root:step 142000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3124e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8891, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005486359596252442
INFO:root:average time for training is 0.005879091501235962
INFO:root:==============================
INFO:root:step 143000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3661e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8892, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9913e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000093

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005444490909576416
INFO:root:average time for training is 0.005838588237762451
INFO:root:==============================
INFO:root:step 144000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3041e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8891, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.000544881820678711
INFO:root:average time for training is 0.005867444753646851
INFO:root:==============================
INFO:root:step 145000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3098e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8891, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005455198287963867
INFO:root:average time for training is 0.005856360912322998
INFO:root:==============================
INFO:root:step 146000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3270e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8891, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005447523593902588
INFO:root:average time for training is 0.005851710796356201
INFO:root:==============================
INFO:root:step 147000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3105e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8891, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9997e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.000541926383972168
INFO:root:average time for training is 0.00584833812713623
INFO:root:==============================
INFO:root:step 148000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3223e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8891, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005483365058898925
INFO:root:average time for training is 0.005858194828033447
INFO:root:==============================
INFO:root:step 149000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3516e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8892, grad_fn=<ProdBackward0>)
log_mean is tensor(-9.9974e-05, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005207517147064209
INFO:root:average time for training is 0.005762802124023437
INFO:root:==============================
INFO:root:step 150000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3139e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8889, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005173358917236328
INFO:root:average time for training is 0.005735888957977295
INFO:root:==============================
INFO:root:step 151000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3096e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8890, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005502159595489502
INFO:root:average time for training is 0.005880837678909302
INFO:root:==============================
INFO:root:step 152000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3494e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8891, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005449080467224122
INFO:root:average time for training is 0.005832108259201049
INFO:root:==============================
INFO:root:step 153000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3595e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8891, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005504217147827148
INFO:root:average time for training is 0.0059086551666259765
INFO:root:==============================
INFO:root:step 154000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3744e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8890, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005333256721496582
INFO:root:average time for training is 0.0057819123268127446
INFO:root:==============================
INFO:root:step 155000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3740e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8890, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005502254962921143
INFO:root:average time for training is 0.005870364904403687
INFO:root:==============================
INFO:root:step 156000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3708e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8890, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005502288341522217
INFO:root:average time for training is 0.005885898351669311
INFO:root:==============================
INFO:root:step 157000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3363e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8888, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005512688159942627
INFO:root:average time for training is 0.005904214382171631
INFO:root:==============================
INFO:root:step 158000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3422e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8887, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005813035964965821
INFO:root:average time for training is 0.006418114423751831
INFO:root:==============================
INFO:root:step 159000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3584e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8886, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005667028427124023
INFO:root:average time for training is 0.0060498988628387455
INFO:root:==============================
INFO:root:step 160000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4303e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8887, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005749757289886475
INFO:root:average time for training is 0.006133868932723999
INFO:root:==============================
INFO:root:step 161000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3868e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8887, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005658946037292481
INFO:root:average time for training is 0.006075144290924072
INFO:root:==============================
INFO:root:step 162000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3195e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8886, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005670137405395508
INFO:root:average time for training is 0.006041455984115601
INFO:root:==============================
INFO:root:step 163000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3485e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8886, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0006019046306610107
INFO:root:average time for training is 0.006596942663192749
INFO:root:==============================
INFO:root:step 164000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4177e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8886, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.000836113452911377
INFO:root:average time for training is 0.009373530626296997
INFO:root:==============================
INFO:root:step 165000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3222e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8885, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0006086287498474121
INFO:root:average time for training is 0.006631377696990967
INFO:root:==============================
INFO:root:step 166000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4087e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8887, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0007976455688476563
INFO:root:average time for training is 0.00870910668373108
INFO:root:==============================
INFO:root:step 167000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3472e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8887, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0023086080551147463
INFO:root:average time for training is 0.019546329975128174
INFO:root:==============================
INFO:root:step 168000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3124e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8885, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0009053678512573242
INFO:root:average time for training is 0.01006378936767578
INFO:root:==============================
INFO:root:step 169000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3925e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8886, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0012561576366424561
INFO:root:average time for training is 0.014952307224273681
INFO:root:==============================
INFO:root:step 170000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3815e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8886, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0007195205688476562
INFO:root:average time for training is 0.007950396299362183
INFO:root:==============================
INFO:root:step 171000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3031e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8886, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0008295722007751465
INFO:root:average time for training is 0.009237590074539184
INFO:root:==============================
INFO:root:step 172000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4219e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8887, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0008282639980316162
INFO:root:average time for training is 0.009211440324783325
INFO:root:==============================
INFO:root:step 173000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3307e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8886, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0006463110446929931
INFO:root:average time for training is 0.007035508394241333
INFO:root:==============================
INFO:root:step 174000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3731e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8888, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005551135540008545
INFO:root:average time for training is 0.005948184251785278
INFO:root:==============================
INFO:root:step 175000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2733e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8885, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005492491722106933
INFO:root:average time for training is 0.005888300180435181
INFO:root:==============================
INFO:root:step 176000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3853e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8886, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005527515411376953
INFO:root:average time for training is 0.005902768135070801
INFO:root:==============================
INFO:root:step 177000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3662e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8885, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005534794330596923
INFO:root:average time for training is 0.0059369966983795165
INFO:root:==============================
INFO:root:step 178000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4164e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8886, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000100
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.00054864501953125
INFO:root:average time for training is 0.005865578651428223
INFO:root:==============================
INFO:root:step 179000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3314e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8885, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.000549433708190918
INFO:root:average time for training is 0.005890831708908081
INFO:root:==============================
INFO:root:step 180000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3219e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8884, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005518870353698731
INFO:root:average time for training is 0.005904520511627197
INFO:root:==============================
INFO:root:step 181000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3844e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8884, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.000553396463394165
INFO:root:average time for training is 0.005906662940979004
INFO:root:==============================
INFO:root:step 182000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3229e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8884, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005502331256866455
INFO:root:average time for training is 0.005883362770080567
INFO:root:==============================
INFO:root:step 183000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3275e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8883, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.00055184006690979
INFO:root:average time for training is 0.005911355018615723
INFO:root:==============================
INFO:root:step 184000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3754e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8883, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.000549053430557251
INFO:root:average time for training is 0.005927228689193725
INFO:root:==============================
INFO:root:step 185000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3817e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8883, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005204768180847168
INFO:root:average time for training is 0.005746769428253174
INFO:root:==============================
INFO:root:step 186000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3619e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8882, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005564920902252198
INFO:root:average time for training is 0.00603118634223938
INFO:root:==============================
INFO:root:step 187000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4456e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8882, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005545089244842529
INFO:root:average time for training is 0.00591770339012146
INFO:root:==============================
INFO:root:step 188000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3918e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8882, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005501031875610352
INFO:root:average time for training is 0.005888272285461426
INFO:root:==============================
INFO:root:step 189000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3671e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8881, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005473527908325196
INFO:root:average time for training is 0.005871847629547119
INFO:root:==============================
INFO:root:step 190000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3757e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8881, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.000551713228225708
INFO:root:average time for training is 0.005915288209915161
INFO:root:==============================
INFO:root:step 191000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3127e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005480296611785889
INFO:root:average time for training is 0.005926717042922974
INFO:root:==============================
INFO:root:step 192000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3131e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005487604141235352
INFO:root:average time for training is 0.005880063533782959
INFO:root:==============================
INFO:root:step 193000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2664e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005498287677764892
INFO:root:average time for training is 0.0059033877849578855
INFO:root:==============================
INFO:root:step 194000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3431e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8881, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005502920150756836
INFO:root:average time for training is 0.005888348817825318
INFO:root:==============================
INFO:root:step 195000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4204e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8881, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005491414070129395
INFO:root:average time for training is 0.005885268449783325
INFO:root:==============================
INFO:root:step 196000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3702e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005521061420440674
INFO:root:average time for training is 0.0058823745250701906
INFO:root:==============================
INFO:root:step 197000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3869e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.00054899263381958
INFO:root:average time for training is 0.005908663511276245
INFO:root:==============================
INFO:root:step 198000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3983e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8881, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000549785852432251
INFO:root:average time for training is 0.005891836404800415
INFO:root:==============================
INFO:root:step 199000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3796e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8881, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005512118339538574
INFO:root:average time for training is 0.005921437978744507
INFO:root:==============================
INFO:root:step 200000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3432e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000539808988571167
INFO:root:average time for training is 0.005861622333526611
INFO:root:==============================
INFO:root:step 201000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3566e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005500221252441406
INFO:root:average time for training is 0.0058918952941894535
INFO:root:==============================
INFO:root:step 202000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3997e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8881, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005479774475097656
INFO:root:average time for training is 0.0058764200210571285
INFO:root:==============================
INFO:root:step 203000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3624e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8881, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000527076005935669
INFO:root:average time for training is 0.005797590494155884
INFO:root:==============================
INFO:root:step 204000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3085e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8881, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005478928089141846
INFO:root:average time for training is 0.005884625434875488
INFO:root:==============================
INFO:root:step 205000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3813e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8881, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000094

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005512816905975342
INFO:root:average time for training is 0.005885482311248779
INFO:root:==============================
INFO:root:step 206000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3005e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005447602272033691
INFO:root:average time for training is 0.005867009162902832
INFO:root:==============================
INFO:root:step 207000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3696e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005508425235748291
INFO:root:average time for training is 0.005894494295120239
INFO:root:==============================
INFO:root:step 208000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3251e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000551790714263916
INFO:root:average time for training is 0.005896007061004639
INFO:root:==============================
INFO:root:step 209000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3950e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8881, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005506918430328369
INFO:root:average time for training is 0.005921238660812378
INFO:root:==============================
INFO:root:step 210000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3374e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005405740737915039
INFO:root:average time for training is 0.00582839298248291
INFO:root:==============================
INFO:root:step 211000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3579e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005442492961883545
INFO:root:average time for training is 0.005878925085067749
INFO:root:==============================
INFO:root:step 212000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4068e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005506119728088379
INFO:root:average time for training is 0.005907629489898682
INFO:root:==============================
INFO:root:step 213000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3768e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005483646392822265
INFO:root:average time for training is 0.005913281202316284
INFO:root:==============================
INFO:root:step 214000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3670e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005497064590454101
INFO:root:average time for training is 0.005888556480407715
INFO:root:==============================
INFO:root:step 215000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3454e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005468719005584716
INFO:root:average time for training is 0.005880245685577393
INFO:root:==============================
INFO:root:step 216000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3795e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005335693359375
INFO:root:average time for training is 0.005907769680023193
INFO:root:==============================
INFO:root:step 217000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3645e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005531420707702636
INFO:root:average time for training is 0.005922880649566651
INFO:root:==============================
INFO:root:step 218000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4141e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005496683120727539
INFO:root:average time for training is 0.005875962495803833
INFO:root:==============================
INFO:root:step 219000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3645e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005515706539154053
INFO:root:average time for training is 0.005912330150604248
INFO:root:==============================
INFO:root:step 220000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3833e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8881, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005483226776123047
INFO:root:average time for training is 0.005892369508743286
INFO:root:==============================
INFO:root:step 221000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3027e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005529365539550782
INFO:root:average time for training is 0.005951298475265503
INFO:root:==============================
INFO:root:step 222000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4046e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005503506660461426
INFO:root:average time for training is 0.005883308887481689
INFO:root:==============================
INFO:root:step 223000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4138e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000551276445388794
INFO:root:average time for training is 0.0059193563461303715
INFO:root:==============================
INFO:root:step 224000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3501e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005519318580627441
INFO:root:average time for training is 0.005902639627456665
INFO:root:==============================
INFO:root:step 225000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3411e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005281889438629151
INFO:root:average time for training is 0.005792197704315186
INFO:root:==============================
INFO:root:step 226000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3341e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005500497817993164
INFO:root:average time for training is 0.00589897894859314
INFO:root:==============================
INFO:root:step 227000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3812e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005521309375762939
INFO:root:average time for training is 0.005923110723495484
INFO:root:==============================
INFO:root:step 228000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4116e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005528581142425537
INFO:root:average time for training is 0.005906290531158447
INFO:root:==============================
INFO:root:step 229000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3362e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005500302314758301
INFO:root:average time for training is 0.005921641349792481
INFO:root:==============================
INFO:root:step 230000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3504e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005484840869903564
INFO:root:average time for training is 0.005877303123474121
INFO:root:==============================
INFO:root:step 231000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3818e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005477218627929687
INFO:root:average time for training is 0.005897422552108764
INFO:root:==============================
INFO:root:step 232000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3592e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005499401092529297
INFO:root:average time for training is 0.005866724491119385
INFO:root:==============================
INFO:root:step 233000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4113e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005501778125762939
INFO:root:average time for training is 0.005890478134155273
INFO:root:==============================
INFO:root:step 234000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3408e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005546584129333496
INFO:root:average time for training is 0.005923852682113647
INFO:root:==============================
INFO:root:step 235000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3744e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005482079982757569
INFO:root:average time for training is 0.005878126621246338
INFO:root:==============================
INFO:root:step 236000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4595e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8880, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005495462417602539
INFO:root:average time for training is 0.005895925283432007
INFO:root:==============================
INFO:root:step 237000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4111e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005497956275939942
INFO:root:average time for training is 0.005904048204421997
INFO:root:==============================
INFO:root:step 238000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4215e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005507774353027344
INFO:root:average time for training is 0.005900898456573486
INFO:root:==============================
INFO:root:step 239000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3623e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8878, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005511467456817627
INFO:root:average time for training is 0.005888302564620971
INFO:root:==============================
INFO:root:step 240000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3543e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8878, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000552483081817627
INFO:root:average time for training is 0.005919481039047241
INFO:root:==============================
INFO:root:step 241000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4124e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005487058162689209
INFO:root:average time for training is 0.005898789644241333
INFO:root:==============================
INFO:root:step 242000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3722e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8878, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0006356813907623291
INFO:root:average time for training is 0.006737637042999268
INFO:root:==============================
INFO:root:step 243000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4176e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000565648078918457
INFO:root:average time for training is 0.0060222713947296145
INFO:root:==============================
INFO:root:step 244000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4443e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005599987506866455
INFO:root:average time for training is 0.005985744714736938
INFO:root:==============================
INFO:root:step 245000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3422e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8878, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005655107498168945
INFO:root:average time for training is 0.006051352262496948
INFO:root:==============================
INFO:root:step 246000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4193e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005394175052642823
INFO:root:average time for training is 0.0059286274909973145
INFO:root:==============================
INFO:root:step 247000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3545e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8878, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005364325046539306
INFO:root:average time for training is 0.005879356622695923
INFO:root:==============================
INFO:root:step 248000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3559e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8878, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005627846717834472
INFO:root:average time for training is 0.006011619567871094
INFO:root:==============================
INFO:root:step 249000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3312e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8878, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005634791851043701
INFO:root:average time for training is 0.005994587659835815
INFO:root:==============================
INFO:root:step 250000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3382e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8877, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005656073093414307
INFO:root:average time for training is 0.005994922399520874
INFO:root:==============================
INFO:root:step 251000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4382e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8879, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005328550338745117
INFO:root:average time for training is 0.005881083965301514
INFO:root:==============================
INFO:root:step 252000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4386e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8878, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005643124580383301
INFO:root:average time for training is 0.005983670234680175
INFO:root:==============================
INFO:root:step 253000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.2916e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005645627975463867
INFO:root:average time for training is 0.0059952492713928225
INFO:root:==============================
INFO:root:step 254000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3963e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8877, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0008544573783874511
INFO:root:average time for training is 0.008847914695739745
INFO:root:==============================
INFO:root:step 255000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4413e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8878, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005636172294616699
INFO:root:average time for training is 0.00609766697883606
INFO:root:==============================
INFO:root:step 256000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4758e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8878, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005534894466400147
INFO:root:average time for training is 0.005939540147781372
INFO:root:==============================
INFO:root:step 257000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4070e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8877, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000554630994796753
INFO:root:average time for training is 0.005937079906463623
INFO:root:==============================
INFO:root:step 258000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3255e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005520827770233154
INFO:root:average time for training is 0.005918233633041382
INFO:root:==============================
INFO:root:step 259000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3975e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005894017219543457
INFO:root:average time for training is 0.006399514198303223
INFO:root:==============================
INFO:root:step 260000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3463e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005638968944549561
INFO:root:average time for training is 0.006139254331588745
INFO:root:==============================
INFO:root:step 261000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3558e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0006007063388824463
INFO:root:average time for training is 0.006217349767684937
INFO:root:==============================
INFO:root:step 262000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3642e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005508968830108642
INFO:root:average time for training is 0.005890299081802369
INFO:root:==============================
INFO:root:step 263000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3656e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005548920631408691
INFO:root:average time for training is 0.005922197103500366
INFO:root:==============================
INFO:root:step 264000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4287e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005501675605773926
INFO:root:average time for training is 0.005877238035202026
INFO:root:==============================
INFO:root:step 265000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4718e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005470490455627441
INFO:root:average time for training is 0.005877522468566895
INFO:root:==============================
INFO:root:step 266000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4129e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000548954963684082
INFO:root:average time for training is 0.005880822896957397
INFO:root:==============================
INFO:root:step 267000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4220e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005507345199584961
INFO:root:average time for training is 0.005903955936431885
INFO:root:==============================
INFO:root:step 268000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3826e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005474450588226318
INFO:root:average time for training is 0.005873826980590821
INFO:root:==============================
INFO:root:step 269000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3557e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000553276538848877
INFO:root:average time for training is 0.005941774845123291
INFO:root:==============================
INFO:root:step 270000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3362e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005569560527801514
INFO:root:average time for training is 0.006008088111877441
INFO:root:==============================
INFO:root:step 271000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3418e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005565855503082275
INFO:root:average time for training is 0.005980747699737549
INFO:root:==============================
INFO:root:step 272000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4200e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005556385517120361
INFO:root:average time for training is 0.005981170415878296
INFO:root:==============================
INFO:root:step 273000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3950e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005568947792053223
INFO:root:average time for training is 0.00595461893081665
INFO:root:==============================
INFO:root:step 274000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4236e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005499250888824463
INFO:root:average time for training is 0.005911724090576172
INFO:root:==============================
INFO:root:step 275000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3936e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005516238212585449
INFO:root:average time for training is 0.005904575109481811
INFO:root:==============================
INFO:root:step 276000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4016e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005502698421478271
INFO:root:average time for training is 0.0058970839977264405
INFO:root:==============================
INFO:root:step 277000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3126e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000554694652557373
INFO:root:average time for training is 0.005953598260879517
INFO:root:==============================
INFO:root:step 278000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3693e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005476832389831543
INFO:root:average time for training is 0.005889430284500122
INFO:root:==============================
INFO:root:step 279000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4016e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005480659008026123
INFO:root:average time for training is 0.0058961896896362305
INFO:root:==============================
INFO:root:step 280000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4592e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000101
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005554757118225097
INFO:root:average time for training is 0.0059703998565673825
INFO:root:==============================
INFO:root:step 281000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4026e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8876, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005574142932891846
INFO:root:average time for training is 0.005951221942901611
INFO:root:==============================
INFO:root:step 282000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3858e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005545010566711426
INFO:root:average time for training is 0.005962365865707397
INFO:root:==============================
INFO:root:step 283000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3880e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005516378879547119
INFO:root:average time for training is 0.005942833662033081
INFO:root:==============================
INFO:root:step 284000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3741e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005490424633026123
INFO:root:average time for training is 0.0059002056121826175
INFO:root:==============================
INFO:root:step 285000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3785e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005472793579101563
INFO:root:average time for training is 0.00588114070892334
INFO:root:==============================
INFO:root:step 286000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3743e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005479042530059815
INFO:root:average time for training is 0.005873377561569214
INFO:root:==============================
INFO:root:step 287000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3288e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005384495258331298
INFO:root:average time for training is 0.0058327107429504395
INFO:root:==============================
INFO:root:step 288000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3200e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005487923622131348
INFO:root:average time for training is 0.005895377397537232
INFO:root:==============================
INFO:root:step 289000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3286e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005437815189361572
INFO:root:average time for training is 0.005885881662368774
INFO:root:==============================
INFO:root:step 290000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4402e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000526968240737915
INFO:root:average time for training is 0.005833755254745484
INFO:root:==============================
INFO:root:step 291000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3773e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005393154621124267
INFO:root:average time for training is 0.005874845266342163
INFO:root:==============================
INFO:root:step 292000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3909e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005394783020019531
INFO:root:average time for training is 0.005859993696212769
INFO:root:==============================
INFO:root:step 293000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3231e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000548961877822876
INFO:root:average time for training is 0.005894442796707153
INFO:root:==============================
INFO:root:step 294000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4135e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005496809482574463
INFO:root:average time for training is 0.005893749952316284
INFO:root:==============================
INFO:root:step 295000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3779e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005493152141571045
INFO:root:average time for training is 0.005888279914855957
INFO:root:==============================
INFO:root:step 296000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3704e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005538880825042725
INFO:root:average time for training is 0.005921102523803711
INFO:root:==============================
INFO:root:step 297000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4050e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005584564208984374
INFO:root:average time for training is 0.005999926805496216
INFO:root:==============================
INFO:root:step 298000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3540e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005279502868652344
INFO:root:average time for training is 0.005826349020004272
INFO:root:==============================
INFO:root:step 299000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3117e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000553459644317627
INFO:root:average time for training is 0.005907852172851563
INFO:root:==============================
INFO:root:step 300000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3524e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000527721643447876
INFO:root:average time for training is 0.005776492357254029
INFO:root:==============================
INFO:root:step 301000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4213e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005473825931549073
INFO:root:average time for training is 0.0059158244132995605
INFO:root:==============================
INFO:root:step 302000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3778e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000556051254272461
INFO:root:average time for training is 0.005972583532333374
INFO:root:==============================
INFO:root:step 303000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3736e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005542707443237305
INFO:root:average time for training is 0.005975351095199585
INFO:root:==============================
INFO:root:step 304000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4210e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005498738288879395
INFO:root:average time for training is 0.005923327922821045
INFO:root:==============================
INFO:root:step 305000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4385e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005278515815734863
INFO:root:average time for training is 0.005802474021911621
INFO:root:==============================
INFO:root:step 306000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4461e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000554069995880127
INFO:root:average time for training is 0.005959562063217163
INFO:root:==============================
INFO:root:step 307000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3941e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005564136505126953
INFO:root:average time for training is 0.00600600004196167
INFO:root:==============================
INFO:root:step 308000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4051e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000552004098892212
INFO:root:average time for training is 0.005941847801208496
INFO:root:==============================
INFO:root:step 309000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3902e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005567660331726074
INFO:root:average time for training is 0.005949682235717774
INFO:root:==============================
INFO:root:step 310000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4505e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8875, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000554760456085205
INFO:root:average time for training is 0.005913428544998169
INFO:root:==============================
INFO:root:step 311000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4371e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005494806766510009
INFO:root:average time for training is 0.005875150442123413
INFO:root:==============================
INFO:root:step 312000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3514e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005501368045806884
INFO:root:average time for training is 0.005888020515441895
INFO:root:==============================
INFO:root:step 313000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4023e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005496582984924317
INFO:root:average time for training is 0.005898425340652466
INFO:root:==============================
INFO:root:step 314000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3705e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005508697032928466
INFO:root:average time for training is 0.005891628265380859
INFO:root:==============================
INFO:root:step 315000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3758e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005546565055847168
INFO:root:average time for training is 0.005940692663192749
INFO:root:==============================
INFO:root:step 316000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3501e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005353636741638184
INFO:root:average time for training is 0.00590798544883728
INFO:root:==============================
INFO:root:step 317000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3509e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005652098655700683
INFO:root:average time for training is 0.006077986717224121
INFO:root:==============================
INFO:root:step 318000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3847e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005548899173736572
INFO:root:average time for training is 0.005999375343322754
INFO:root:==============================
INFO:root:step 319000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4514e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0007671716213226319
INFO:root:average time for training is 0.007285151243209839
INFO:root:==============================
INFO:root:step 320000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3576e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0006705708503723144
INFO:root:average time for training is 0.007346180677413941
INFO:root:==============================
INFO:root:step 321000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3669e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005663983821868896
INFO:root:average time for training is 0.0061205456256866455
INFO:root:==============================
INFO:root:step 322000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4618e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005583035945892334
INFO:root:average time for training is 0.006032209634780883
INFO:root:==============================
INFO:root:step 323000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3999e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0006435384750366211
INFO:root:average time for training is 0.007038890838623047
INFO:root:==============================
INFO:root:step 324000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3587e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0006330060958862305
INFO:root:average time for training is 0.006800015449523925
INFO:root:==============================
INFO:root:step 325000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3488e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005589671134948731
INFO:root:average time for training is 0.006176686525344849
INFO:root:==============================
INFO:root:step 326000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3727e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005878727436065674
INFO:root:average time for training is 0.00628835654258728
INFO:root:==============================
INFO:root:step 327000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3681e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005974955558776855
INFO:root:average time for training is 0.006465173959732055
INFO:root:==============================
INFO:root:step 328000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3347e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0006129910945892334
INFO:root:average time for training is 0.006716604709625244
INFO:root:==============================
INFO:root:step 329000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3464e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005680966377258301
INFO:root:average time for training is 0.006041038036346436
INFO:root:==============================
INFO:root:step 330000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4627e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005653674602508545
INFO:root:average time for training is 0.006063652038574219
INFO:root:==============================
INFO:root:step 331000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3788e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000556347131729126
INFO:root:average time for training is 0.005979844570159912
INFO:root:==============================
INFO:root:step 332000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4082e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005830464363098145
INFO:root:average time for training is 0.006363554954528809
INFO:root:==============================
INFO:root:step 333000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3645e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005648655891418457
INFO:root:average time for training is 0.006133869886398315
INFO:root:==============================
INFO:root:step 334000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4465e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005413775444030762
INFO:root:average time for training is 0.0058536679744720455
INFO:root:==============================
INFO:root:step 335000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3933e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000550706148147583
INFO:root:average time for training is 0.005905826807022094
INFO:root:==============================
INFO:root:step 336000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4262e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005500690937042237
INFO:root:average time for training is 0.005907401323318482
INFO:root:==============================
INFO:root:step 337000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3726e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005479044914245605
INFO:root:average time for training is 0.0059035437107086185
INFO:root:==============================
INFO:root:step 338000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4477e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005497422218322754
INFO:root:average time for training is 0.005894492149353028
INFO:root:==============================
INFO:root:step 339000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4241e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005502188205718994
INFO:root:average time for training is 0.0059253621101379396
INFO:root:==============================
INFO:root:step 340000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3931e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005489451885223389
INFO:root:average time for training is 0.00589927339553833
INFO:root:==============================
INFO:root:step 341000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3895e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005580527782440186
INFO:root:average time for training is 0.005992976665496827
INFO:root:==============================
INFO:root:step 342000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3811e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005661897659301758
INFO:root:average time for training is 0.006139798402786255
INFO:root:==============================
INFO:root:step 343000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3759e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005528407096862793
INFO:root:average time for training is 0.005906841993331909
INFO:root:==============================
INFO:root:step 344000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4049e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005533361434936524
INFO:root:average time for training is 0.005888306617736817
INFO:root:==============================
INFO:root:step 345000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4267e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005228481292724609
INFO:root:average time for training is 0.005744763612747192
INFO:root:==============================
INFO:root:step 346000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3663e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005522451400756836
INFO:root:average time for training is 0.00591136384010315
INFO:root:==============================
INFO:root:step 347000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4253e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000581031322479248
INFO:root:average time for training is 0.006161110162734985
INFO:root:==============================
INFO:root:step 348000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4565e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005672295093536377
INFO:root:average time for training is 0.00609795618057251
INFO:root:==============================
INFO:root:step 349000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4635e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005526876449584961
INFO:root:average time for training is 0.005955937147140503
INFO:root:==============================
INFO:root:step 350000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4429e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005536453723907471
INFO:root:average time for training is 0.005956231117248535
INFO:root:==============================
INFO:root:step 351000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3844e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005512557029724121
INFO:root:average time for training is 0.0059063520431518555
INFO:root:==============================
INFO:root:step 352000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4130e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005544407367706299
INFO:root:average time for training is 0.005974113702774048
INFO:root:==============================
INFO:root:step 353000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4089e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000524005651473999
INFO:root:average time for training is 0.005758933782577515
INFO:root:==============================
INFO:root:step 354000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4168e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005244529247283936
INFO:root:average time for training is 0.005766029357910156
INFO:root:==============================
INFO:root:step 355000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4214e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005367541313171387
INFO:root:average time for training is 0.005835781812667847
INFO:root:==============================
INFO:root:step 356000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3028e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005496625900268555
INFO:root:average time for training is 0.005905665397644043
INFO:root:==============================
INFO:root:step 357000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4440e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000558549165725708
INFO:root:average time for training is 0.006004796743392944
INFO:root:==============================
INFO:root:step 358000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3681e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005504016876220703
INFO:root:average time for training is 0.005914747714996338
INFO:root:==============================
INFO:root:step 359000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4011e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000560781478881836
INFO:root:average time for training is 0.00606518006324768
INFO:root:==============================
INFO:root:step 360000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3995e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000563086986541748
INFO:root:average time for training is 0.006108771800994873
INFO:root:==============================
INFO:root:step 361000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4626e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005636942386627197
INFO:root:average time for training is 0.006057350158691406
INFO:root:==============================
INFO:root:step 362000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3897e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005520122051239013
INFO:root:average time for training is 0.005894451379776001
INFO:root:==============================
INFO:root:step 363000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3739e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005536441802978516
INFO:root:average time for training is 0.005903415679931641
INFO:root:==============================
INFO:root:step 364000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3815e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005501556396484375
INFO:root:average time for training is 0.005893267393112182
INFO:root:==============================
INFO:root:step 365000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4786e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000553023338317871
INFO:root:average time for training is 0.005910972595214844
INFO:root:==============================
INFO:root:step 366000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3844e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005215709209442139
INFO:root:average time for training is 0.005741876363754272
INFO:root:==============================
INFO:root:step 367000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3645e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.00055452299118042
INFO:root:average time for training is 0.005942747831344604
INFO:root:==============================
INFO:root:step 368000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3788e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005546023845672607
INFO:root:average time for training is 0.005934159994125366
INFO:root:==============================
INFO:root:step 369000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4663e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000551063060760498
INFO:root:average time for training is 0.005926136255264282
INFO:root:==============================
INFO:root:step 370000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4814e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005500910282135009
INFO:root:average time for training is 0.005895797252655029
INFO:root:==============================
INFO:root:step 371000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4611e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005491182804107666
INFO:root:average time for training is 0.005902889728546142
INFO:root:==============================
INFO:root:step 372000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3669e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005507378578186035
INFO:root:average time for training is 0.005914268493652344
INFO:root:==============================
INFO:root:step 373000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3092e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005489976406097412
INFO:root:average time for training is 0.005894689083099365
INFO:root:==============================
INFO:root:step 374000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3342e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000548551082611084
INFO:root:average time for training is 0.005876499176025391
INFO:root:==============================
INFO:root:step 375000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4715e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005474505424499512
INFO:root:average time for training is 0.005882364749908447
INFO:root:==============================
INFO:root:step 376000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3618e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005518925189971923
INFO:root:average time for training is 0.0058707654476165775
INFO:root:==============================
INFO:root:step 377000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3822e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005494356155395508
INFO:root:average time for training is 0.005899608373641968
INFO:root:==============================
INFO:root:step 378000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3359e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000555495023727417
INFO:root:average time for training is 0.006009296178817749
INFO:root:==============================
INFO:root:step 379000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3913e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005687377452850341
INFO:root:average time for training is 0.006166198968887329
INFO:root:==============================
INFO:root:step 380000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4814e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005636470317840576
INFO:root:average time for training is 0.006066927433013916
INFO:root:==============================
INFO:root:step 381000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4507e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005564494132995606
INFO:root:average time for training is 0.005983829736709595
INFO:root:==============================
INFO:root:step 382000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4398e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005491926670074463
INFO:root:average time for training is 0.005872943639755249
INFO:root:==============================
INFO:root:step 383000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3797e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005499207973480224
INFO:root:average time for training is 0.005920311450958252
INFO:root:==============================
INFO:root:step 384000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4466e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000549004316329956
INFO:root:average time for training is 0.0058794100284576415
INFO:root:==============================
INFO:root:step 385000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3678e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005514438152313232
INFO:root:average time for training is 0.005910592794418335
INFO:root:==============================
INFO:root:step 386000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3799e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005492155551910401
INFO:root:average time for training is 0.005868366718292236
INFO:root:==============================
INFO:root:step 387000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4115e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005520694255828857
INFO:root:average time for training is 0.0058805525302886965
INFO:root:==============================
INFO:root:step 388000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3468e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005503301620483398
INFO:root:average time for training is 0.005917868375778198
INFO:root:==============================
INFO:root:step 389000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3575e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005486702919006348
INFO:root:average time for training is 0.005908405780792237
INFO:root:==============================
INFO:root:step 390000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3455e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005242643356323242
INFO:root:average time for training is 0.005773262500762939
INFO:root:==============================
INFO:root:step 391000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3994e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005479669570922852
INFO:root:average time for training is 0.005902165651321411
INFO:root:==============================
INFO:root:step 392000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3801e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005494253635406494
INFO:root:average time for training is 0.005890419483184814
INFO:root:==============================
INFO:root:step 393000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4169e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000546818494796753
INFO:root:average time for training is 0.005871271371841431
INFO:root:==============================
INFO:root:step 394000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3763e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005481481552124023
INFO:root:average time for training is 0.005886990308761597
INFO:root:==============================
INFO:root:step 395000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3821e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005523848533630371
INFO:root:average time for training is 0.005925291538238525
INFO:root:==============================
INFO:root:step 396000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3194e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005496947765350342
INFO:root:average time for training is 0.005885790586471557
INFO:root:==============================
INFO:root:step 397000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4572e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005491206645965576
INFO:root:average time for training is 0.005904986143112183
INFO:root:==============================
INFO:root:step 398000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3694e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005746910572052002
INFO:root:average time for training is 0.006134620904922485
INFO:root:==============================
INFO:root:step 399000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3151e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0008452193737030029
INFO:root:average time for training is 0.008646617174148559
INFO:root:==============================
INFO:root:step 400000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4492e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000541022539138794
INFO:root:average time for training is 0.005865853309631347
INFO:root:==============================
INFO:root:step 401000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3564e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005501139163970947
INFO:root:average time for training is 0.005905644178390503
INFO:root:==============================
INFO:root:step 402000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3471e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005587527751922608
INFO:root:average time for training is 0.00598546028137207
INFO:root:==============================
INFO:root:step 403000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4512e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005494644641876221
INFO:root:average time for training is 0.0058861315250396725
INFO:root:==============================
INFO:root:step 404000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3446e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005513253211975097
INFO:root:average time for training is 0.005916361570358276
INFO:root:==============================
INFO:root:step 405000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4103e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005224003791809083
INFO:root:average time for training is 0.005768832683563233
INFO:root:==============================
INFO:root:step 406000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3598e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005482676029205323
INFO:root:average time for training is 0.005890530824661255
INFO:root:==============================
INFO:root:step 407000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4060e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005517444610595704
INFO:root:average time for training is 0.005888320684432983
INFO:root:==============================
INFO:root:step 408000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4140e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005514700412750244
INFO:root:average time for training is 0.0058733229637146
INFO:root:==============================
INFO:root:step 409000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4324e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.000550546646118164
INFO:root:average time for training is 0.005892942905426026
INFO:root:==============================
INFO:root:step 410000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4788e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8874, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005537841320037842
INFO:root:average time for training is 0.005913126945495606
INFO:root:==============================
INFO:root:step 411000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3386e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005984418392181397
INFO:root:average time for training is 0.006550321340560913
INFO:root:==============================
INFO:root:step 412000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4270e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0006228251457214356
INFO:root:average time for training is 0.006745814561843872
INFO:root:==============================
INFO:root:step 413000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3677e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8872, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005689136981964112
INFO:root:average time for training is 0.006467733383178711
INFO:root:==============================
INFO:root:step 414000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4530e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0008776915073394775
INFO:root:average time for training is 0.00950788688659668
INFO:root:==============================
INFO:root:step 415000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4228e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0006281540393829345
INFO:root:average time for training is 0.006890220642089844
INFO:root:==============================
INFO:root:step 416000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.4026e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

INFO:root:average time for data accessing is 0.0005856287479400634
INFO:root:average time for training is 0.0063358526229858395
INFO:root:==============================
INFO:root:step 417000
INFO:root:------------------------------
INFO:root:training loss is tensor(-9.3782e-06, grad_fn=<NegBackward>)

INFO:root:the portfolio value on test set is tensor(0.8873, grad_fn=<ProdBackward0>)
log_mean is tensor(-0.0001, grad_fn=<MeanBackward0>)
loss_value is 0.000102
log mean without commission fee is -0.000095

INFO:root:==============================

